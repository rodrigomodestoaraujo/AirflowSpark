[2024-10-24T01:26:57.247+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [queued]>
[2024-10-24T01:26:57.266+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [queued]>
[2024-10-24T01:26:57.267+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 3
[2024-10-24T01:26:57.426+0000] {taskinstance.py:1380} INFO - Executing <Task(SparkSubmitOperator): Silver> on 2023-11-28 08:00:00+00:00
[2024-10-24T01:26:57.439+0000] {standard_task_runner.py:57} INFO - Started process 8819 to run task
[2024-10-24T01:26:57.449+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_openbrewerydb_to_silver_gold', 'Silver', 'scheduled__2023-11-28T08:00:00+00:00', '--job-id', '137', '--raw', '--subdir', 'DAGS_FOLDER/api_openbrewerydb_to_silver.py', '--cfg-path', '/tmp/tmpafumcffr']
[2024-10-24T01:26:57.459+0000] {standard_task_runner.py:85} INFO - Job 137: Subtask Silver
[2024-10-24T01:26:57.622+0000] {task_command.py:415} INFO - Running <TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [running]> on host de5108c6da1d
[2024-10-24T01:26:57.897+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Rodrigo Araujo' AIRFLOW_CTX_DAG_ID='api_openbrewerydb_to_silver_gold' AIRFLOW_CTX_TASK_ID='Silver' AIRFLOW_CTX_EXECUTION_DATE='2023-11-28T08:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-11-28T08:00:00+00:00'
[2024-10-24T01:26:57.970+0000] {base.py:73} INFO - Using connection ID 'spark-conn' for task execution.
[2024-10-24T01:26:57.972+0000] {spark_submit.py:363} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --name arrow-spark --queue root.default jobs/silver/api_openbrewerydb.py
[2024-10-24T01:27:28.341+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:28 INFO SparkContext: Running Spark version 3.5.3
[2024-10-24T01:27:28.347+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:28 INFO SparkContext: OS info Linux, 5.15.0-124-generic, amd64
[2024-10-24T01:27:28.359+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:28 INFO SparkContext: Java version 11.0.25
[2024-10-24T01:27:28.877+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-10-24T01:27:29.554+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceUtils: ==============================================================
[2024-10-24T01:27:29.556+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-10-24T01:27:29.558+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceUtils: ==============================================================
[2024-10-24T01:27:29.559+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO SparkContext: Submitted application: IngestaoSilver
[2024-10-24T01:27:29.757+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-10-24T01:27:29.896+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceProfile: Limiting resource is cpu
[2024-10-24T01:27:29.902+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-10-24T01:27:30.450+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:30 INFO SecurityManager: Changing view acls to: ***
[2024-10-24T01:27:30.460+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:30 INFO SecurityManager: Changing modify acls to: ***
[2024-10-24T01:27:30.474+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:30 INFO SecurityManager: Changing view acls groups to:
[2024-10-24T01:27:30.482+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:30 INFO SecurityManager: Changing modify acls groups to:
[2024-10-24T01:27:30.484+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2024-10-24T01:27:34.116+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:34 INFO Utils: Successfully started service 'sparkDriver' on port 39515.
[2024-10-24T01:27:34.506+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:34 INFO SparkEnv: Registering MapOutputTracker
[2024-10-24T01:27:34.747+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:34 INFO SparkEnv: Registering BlockManagerMaster
[2024-10-24T01:27:35.043+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-10-24T01:27:35.045+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-10-24T01:27:35.087+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-10-24T01:27:35.361+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-21b10aa8-ead3-4170-8ac0-cbed9ddaaca6
[2024-10-24T01:27:35.407+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-10-24T01:27:35.560+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:35 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-10-24T01:27:37.378+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:37 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-10-24T01:27:37.931+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2024-10-24T01:27:37.937+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[2024-10-24T01:27:37.964+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:37 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[2024-10-24T01:27:38.088+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:38 INFO Utils: Successfully started service 'SparkUI' on port 4043.
[2024-10-24T01:27:39.607+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-10-24T01:27:40.436+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:40 INFO TransportClientFactory: Successfully created connection to spark-master/172.22.0.3:7077 after 689 ms (0 ms spent in bootstraps)
[2024-10-24T01:27:42.051+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241024012741-0046
[2024-10-24T01:27:42.079+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35337.
[2024-10-24T01:27:42.079+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO NettyBlockTransferService: Server created on de5108c6da1d:35337
[2024-10-24T01:27:42.080+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-10-24T01:27:42.099+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, de5108c6da1d, 35337, None)
[2024-10-24T01:27:42.110+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO BlockManagerMasterEndpoint: Registering block manager de5108c6da1d:35337 with 434.4 MiB RAM, BlockManagerId(driver, de5108c6da1d, 35337, None)
[2024-10-24T01:27:42.156+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, de5108c6da1d, 35337, None)
[2024-10-24T01:27:42.160+0000] {spark_submit.py:524} INFO - 24/10/24 01:27:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, de5108c6da1d, 35337, None)
[2024-10-24T01:29:24.947+0000] {spark_submit.py:524} INFO - 24/10/24 01:29:24 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener HeartbeatReceiver took 17.786728546s.
[2024-10-24T01:29:29.550+0000] {spark_submit.py:524} INFO - 24/10/24 01:29:29 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener AppStatusListener took 23.647446891s.
[2024-10-24T01:29:30.827+0000] {spark_submit.py:524} INFO - 24/10/24 01:29:30 INFO AsyncEventQueue: Process of event SparkListenerBlockManagerAdded(1729733262108,BlockManagerId(driver, de5108c6da1d, 35337, None),455501414,Some(455501414),Some(0)) by listener AppStatusListener took 1.055003691s.
[2024-10-24T01:29:34.854+0000] {spark_submit.py:524} INFO - 24/10/24 01:29:34 INFO AsyncEventQueue: Process of event SparkListenerEnvironmentUpdate(Map(Spark Properties -> ArrayBuffer((spark.app.id,app-20241024012741-0046), (spark.app.name,IngestaoSilver), (spark.app.startTime,1729733248237), (spark.app.submitTime,1729733239389), (spark.driver.extraJavaOptions,-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false), (spark.driver.host,de5108c6da1d), (spark.driver.port,39515), (spark.executor.extraJavaOptions,-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false), (spark.executor.id,driver), (spark.master,spark://spark-master:7077), (spark.rdd.compress,True), (spark.scheduler.mode,FIFO), (spark.serializer.objectStreamReset,100), (spark.submit.deployMode,client), (spark.submit.pyFiles,)), Classpath Entries -> Vector((/home/***/.local/lib/python3.11/site-packages/pyspark/conf,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/HikariCP-2.5.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/JLargeArrays-1.5.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/JTransforms-3.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/RoaringBitmap-0.9.45.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/ST4-4.0.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/activation-1.1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/aircompressor-0.27.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/algebra_2.12-2.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/annotations-17.0.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/antlr-runtime-3.5.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/antlr4-runtime-4.9.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/aopalliance-repackaged-2.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arpack-3.0.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arpack_combined_all-0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arrow-format-12.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arrow-memory-core-12.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arrow-memory-netty-12.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/arrow-vector-12.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/audience-annotations-0.5.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/avro-1.11.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/avro-ipc-1.11.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/avro-mapred-1.11.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/blas-3.0.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/bonecp-0.8.0.RELEASE.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/breeze-macros_2.12-2.1.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/breeze_2.12-2.1.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/cats-kernel_2.12-2.1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/chill-java-0.10.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/chill_2.12-0.10.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-cli-1.5.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-codec-1.16.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-collections-3.2.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-collections4-4.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-compiler-3.1.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-compress-1.23.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-crypto-1.1.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-dbcp-1.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-io-2.16.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-lang-2.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-lang3-3.12.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-logging-1.1.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-math3-3.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-pool-1.5.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/commons-text-1.10.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/compress-lzf-1.1.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/curator-client-2.13.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/curator-framework-2.13.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/curator-recipes-2.13.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/datanucleus-api-jdo-4.2.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/datanucleus-core-4.1.17.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/datanucleus-rdbms-4.1.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/datasketches-java-3.3.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/datasketches-memory-2.1.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/derby-10.14.2.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/flatbuffers-java-1.12.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/gson-2.2.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/guava-14.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hadoop-client-api-3.3.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hadoop-client-runtime-3.3.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hadoop-shaded-guava-1.1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-beeline-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-cli-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-common-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-exec-2.3.9-core.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-jdbc-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-llap-common-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-metastore-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-serde-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-service-rpc-3.1.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-shims-0.23-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-shims-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-shims-common-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-shims-scheduler-2.3.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hive-storage-api-2.8.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hk2-api-2.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hk2-locator-2.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/hk2-utils-2.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/httpclient-4.5.14.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/httpcore-4.4.16.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/istack-commons-runtime-3.0.8.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-annotations-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-core-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-core-asl-1.9.13.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-databind-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-dataformat-yaml-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-datatype-jsr310-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-mapper-asl-1.9.13.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jackson-module-scala_2.12-2.15.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.annotation-api-1.3.5.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.inject-2.6.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.servlet-api-4.0.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.validation-api-2.0.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/janino-3.1.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/javassist-3.29.2-GA.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/javax.jdo-3.2.0-m3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/javolution-5.5.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jaxb-runtime-2.3.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jcl-over-slf4j-2.0.7.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jdo-api-3.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-client-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-common-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-container-servlet-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-container-servlet-core-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-hk2-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jersey-server-2.40.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jline-2.14.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/joda-time-2.12.5.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jodd-core-3.5.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jpam-1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/json-1.8.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jsr305-3.0.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jta-1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/jul-to-slf4j-2.0.7.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kryo-shaded-4.0.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-client-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-client-api-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-httpclient-okhttp-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-admissionregistration-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-apiextensions-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-apps-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-autoscaling-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-batch-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-certificates-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-common-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-coordination-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-core-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-discovery-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-events-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-extensions-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-flowcontrol-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-gatewayapi-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-metrics-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-networking-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-node-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-policy-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-rbac-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-resource-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-scheduling-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/kubernetes-model-storageclass-6.7.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/lapack-3.0.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/leveldbjni-all-1.8.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/libfb303-0.9.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/libthrift-0.12.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/log4j-1.2-api-2.20.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/log4j-api-2.20.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/log4j-core-2.20.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/log4j-slf4j2-impl-2.20.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/logging-interceptor-3.12.12.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/lz4-java-1.8.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/metrics-core-4.2.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/metrics-graphite-4.2.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/metrics-jmx-4.2.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/metrics-json-4.2.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/metrics-jvm-4.2.19.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/minlog-1.3.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-all-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-buffer-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-codec-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-codec-http-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-codec-http2-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-codec-socks-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-common-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-handler-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-handler-proxy-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-resolver-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-classes-epoll-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-classes-kqueue-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/netty-transport-native-unix-common-4.1.96.Final.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/objenesis-3.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/okhttp-3.12.12.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/okio-1.17.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/opencsv-2.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/orc-core-1.9.4-shaded-protobuf.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/orc-mapreduce-1.9.4-shaded-protobuf.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/orc-shims-1.9.4.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/oro-2.0.8.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/osgi-resource-locator-1.0.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/paranamer-2.8.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-column-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-common-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-encoding-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-format-structures-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-hadoop-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/parquet-jackson-1.13.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/pickle-1.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/py4j-0.10.9.7.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/rocksdbjni-8.3.2.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-collection-compat_2.12-2.7.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-compiler-2.12.18.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-library-2.12.18.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-parser-combinators_2.12-2.3.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-reflect-2.12.18.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/scala-xml_2.12-2.1.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/shims-0.9.45.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/slf4j-api-2.0.7.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/snakeyaml-2.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/snakeyaml-engine-2.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/snappy-java-1.1.10.5.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-catalyst_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-common-utils_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-graphx_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-hive-thriftserver_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-hive_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-kubernetes_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-kvstore_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-launcher_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-mesos_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-mllib-local_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-mllib_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-network-common_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-network-shuffle_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-repl_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-sketch_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-sql-api_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-sql_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-streaming_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-tags_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-unsafe_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spark-yarn_2.12-3.5.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spire-macros_2.12-0.17.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spire-platform_2.12-0.17.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spire-util_2.12-0.17.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/spire_2.12-0.17.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/stax-api-1.0.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/stream-2.9.6.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/super-csv-2.2.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/threeten-extra-1.7.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/tink-1.9.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/transaction-api-1.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/univocity-parsers-2.9.1.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/xbean-asm9-shaded-4.23.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/xz-1.9.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/zjsonpatch-0.3.0.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/zookeeper-3.6.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/zookeeper-jute-3.6.3.jar,System Classpath), (/home/***/.local/lib/python3.11/site-packages/pyspark/jars/zstd-jni-1.5.5-4.jar,System Classpath)), Hadoop Properties -> List((adl.feature.ownerandgroup.enableupn,false), (adl.http.timeout,-1), (dfs.client.ignore.namenode.default.kms.uri,false), (dfs.ha.fencing.ssh.connect-timeout,30000), (file.blocksize,67108864), (file.bytes-per-checksum,512), (file.client-write-packet-size,65536), (file.replication,1), (file.stream-buffer-size,4096), (fs.AbstractFileSystem.abfs.impl,org.apache.hadoop.fs.azurebfs.Abfs), (fs.AbstractFileSystem.abfss.impl,org.apache.hadoop.fs.azurebfs.Abfss), (fs.AbstractFileSystem.adl.impl,org.apache.hadoop.fs.adl.Adl), (fs.AbstractFileSystem.file.impl,org.apache.hadoop.fs.local.LocalFs), (fs.AbstractFileSystem.ftp.impl,org.apache.hadoop.fs.ftp.FtpFs), (fs.AbstractFileSystem.gs.impl,com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS), (fs.AbstractFileSystem.har.impl,org.apache.hadoop.fs.HarFs), (fs.AbstractFileSystem.hdfs.impl,org.apache.hadoop.fs.Hdfs), (fs.AbstractFileSystem.s3a.impl,org.apache.hadoop.fs.s3a.S3A), (fs.AbstractFileSystem.swebhdfs.impl,org.apache.hadoop.fs.SWebHdfs), (fs.AbstractFileSystem.viewfs.impl,org.apache.hadoop.fs.viewfs.ViewFs), (fs.AbstractFileSystem.wasb.impl,org.apache.hadoop.fs.azure.Wasb), (fs.AbstractFileSystem.wasbs.impl,org.apache.hadoop.fs.azure.Wasbs), (fs.AbstractFileSystem.webhdfs.impl,org.apache.hadoop.fs.WebHdfs), (fs.abfs.impl,org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem), (fs.abfss.impl,org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem), (fs.adl.impl,org.apache.hadoop.fs.adl.AdlFileSystem), (fs.adl.oauth2.access.token.provider.type,*********(redacted)), (fs.automatic.close,true), (fs.azure.authorization,false), (fs.azure.authorization.caching.enable,true), (fs.azure.buffer.dir,${hadoop.tmp.dir}/abfs), (fs.azure.local.sas.key.mode,false), (fs.azure.sas.expiry.period,90d), (fs.azure.saskey.usecontainersaskeyforallaccess,true), (fs.azure.secure.mode,false), (fs.azure.user.agent.prefix,unknown), (fs.client.resolve.remote.symlinks,true), (fs.client.resolve.topology.enabled,false), (fs.defaultFS,file:///), (fs.df.interval,60000), (fs.du.interval,600000), (fs.ftp.data.connection.mode,ACTIVE_LOCAL_DATA_CONNECTION_MODE), (fs.ftp.host,0.0.0.0), (fs.ftp.host.port,21), (fs.ftp.impl,org.apache.hadoop.fs.ftp.FTPFileSystem), (fs.ftp.timeout,0), (fs.ftp.transfer.mode,BLOCK_TRANSFER_MODE), (fs.getspaceused.jitterMillis,60000), (fs.har.impl.disable.cache,true), (fs.permissions.umask-mode,022), (fs.s3a.accesspoint.required,false), (fs.s3a.assumed.role.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider), (fs.s3a.assumed.role.session.duration,30m), (fs.s3a.attempts.maximum,20), (fs.s3a.aws.credentials.provider,
[2024-10-24T01:29:35.652+0000] {spark_submit.py:524} INFO - org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,
[2024-10-24T01:29:36.766+0000] {spark_submit.py:524} INFO - org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,
[2024-10-24T01:29:37.492+0000] {spark_submit.py:524} INFO - com.amazonaws.auth.EnvironmentVariableCredentialsProvider,
[2024-10-24T01:29:40.385+0000] {spark_submit.py:524} INFO - org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider
[2024-10-24T01:29:40.934+0000] {spark_submit.py:524} INFO - ), (fs.s3a.block.size,32M), (fs.s3a.buffer.dir,${hadoop.tmp.dir}/s3a), (fs.s3a.change.detection.mode,server), (fs.s3a.change.detection.source,etag), (fs.s3a.change.detection.version.required,true), (fs.s3a.committer.abort.pending.uploads,true), (fs.s3a.committer.magic.enabled,true), (fs.s3a.committer.name,file), (fs.s3a.committer.staging.conflict-mode,append), (fs.s3a.committer.staging.tmp.path,tmp/staging), (fs.s3a.committer.staging.unique-filenames,true), (fs.s3a.committer.threads,8), (fs.s3a.connection.establish.timeout,5000), (fs.s3a.connection.maximum,96), (fs.s3a.connection.request.timeout,0), (fs.s3a.connection.ssl.enabled,true), (fs.s3a.connection.timeout,200000), (fs.s3a.downgrade.syncable.exceptions,true), (fs.s3a.endpoint,s3.amazonaws.com), (fs.s3a.etag.checksum.enabled,false), (fs.s3a.executor.capacity,16), (fs.s3a.fast.upload.active.blocks,4), (fs.s3a.fast.upload.buffer,disk), (fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem), (fs.s3a.list.version,2), (fs.s3a.max.total.tasks,32), (fs.s3a.metadatastore.authoritative,false), (fs.s3a.metadatastore.fail.on.write.error,true), (fs.s3a.metadatastore.impl,org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore), (fs.s3a.metadatastore.metadata.ttl,15m), (fs.s3a.multiobjectdelete.enable,true), (fs.s3a.multipart.purge,false), (fs.s3a.multipart.purge.age,86400), (fs.s3a.multipart.size,64M), (fs.s3a.multipart.threshold,128M), (fs.s3a.paging.maximum,5000), (fs.s3a.path.style.access,false), (fs.s3a.readahead.range,64K), (fs.s3a.retry.interval,500ms), (fs.s3a.retry.limit,7), (fs.s3a.retry.throttle.interval,100ms), (fs.s3a.retry.throttle.limit,20), (fs.s3a.s3guard.cli.prune.age,86400000), (fs.s3a.s3guard.consistency.retry.interval,2s), (fs.s3a.s3guard.consistency.retry.limit,7), (fs.s3a.s3guard.ddb.background.sleep,25ms), (fs.s3a.s3guard.ddb.max.retries,9), (fs.s3a.s3guard.ddb.table.capacity.read,0), (fs.s3a.s3guard.ddb.table.capacity.write,0), (fs.s3a.s3guard.ddb.table.create,false), (fs.s3a.s3guard.ddb.table.sse.enabled,false), (fs.s3a.s3guard.ddb.throttle.retry.interval,100ms), (fs.s3a.select.enabled,true), (fs.s3a.select.errors.include.sql,false), (fs.s3a.select.input.compression,none), (fs.s3a.select.input.csv.comment.marker,#), (fs.s3a.select.input.csv.field.delimiter,,), (fs.s3a.select.input.csv.header,none), (fs.s3a.select.input.csv.quote.character,"), (fs.s3a.select.input.csv.quote.escape.character,\\), (fs.s3a.select.input.csv.record.delimiter,\n), (fs.s3a.select.output.csv.field.delimiter,,), (fs.s3a.select.output.csv.quote.character,"), (fs.s3a.select.output.csv.quote.escape.character,\\), (fs.s3a.select.output.csv.quote.fields,always), (fs.s3a.select.output.csv.record.delimiter,\n), (fs.s3a.socket.recv.buffer,8192), (fs.s3a.socket.send.buffer,8192), (fs.s3a.ssl.channel.mode,default_jsse), (fs.s3a.threads.keepalivetime,60), (fs.s3a.threads.max,64), (fs.swift.impl,org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem), (fs.trash.checkpoint.interval,0), (fs.trash.interval,0), (fs.viewfs.overload.scheme.target.abfs.impl,org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem), (fs.viewfs.overload.scheme.target.abfss.impl,org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem), (fs.viewfs.overload.scheme.target.file.impl,org.apache.hadoop.fs.LocalFileSystem), (fs.viewfs.overload.scheme.target.ftp.impl,org.apache.hadoop.fs.ftp.FTPFileSystem), (fs.viewfs.overload.scheme.target.gs.impl,com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS), (fs.viewfs.overload.scheme.target.hdfs.impl,org.apache.hadoop.hdfs.DistributedFileSystem), (fs.viewfs.overload.scheme.target.http.impl,org.apache.hadoop.fs.http.HttpFileSystem), (fs.viewfs.overload.scheme.target.https.impl,org.apache.hadoop.fs.http.HttpsFileSystem), (fs.viewfs.overload.scheme.target.o3fs.impl,org.apache.hadoop.fs.ozone.OzoneFileSystem), (fs.viewfs.overload.scheme.target.ofs.impl,org.apache.hadoop.fs.ozone.RootedOzoneFileSystem), (fs.viewfs.overload.scheme.target.oss.impl,org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem), (fs.viewfs.overload.scheme.target.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem), (fs.viewfs.overload.scheme.target.swebhdfs.impl,org.apache.hadoop.hdfs.web.SWebHdfsFileSystem), (fs.viewfs.overload.scheme.target.swift.impl,org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem), (fs.viewfs.overload.scheme.target.wasb.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem), (fs.viewfs.overload.scheme.target.webhdfs.impl,org.apache.hadoop.hdfs.web.WebHdfsFileSystem), (fs.viewfs.rename.strategy,SAME_MOUNTPOINT), (fs.wasb.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem), (fs.wasbs.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure), (ftp.blocksize,67108864), (ftp.bytes-per-checksum,512), (ftp.client-write-packet-size,65536), (ftp.replication,3), (ftp.stream-buffer-size,4096), (ha.failover-controller.active-standby-elector.zk.op.retries,3), (ha.failover-controller.cli-check.rpc-timeout.ms,20000), (ha.failover-controller.graceful-fence.connection.retries,1), (ha.failover-controller.graceful-fence.rpc-timeout.ms,5000), (ha.failover-controller.new-active.rpc-timeout.ms,60000), (ha.health-monitor.check-interval.ms,1000), (ha.health-monitor.connect-retry-interval.ms,1000), (ha.health-monitor.rpc-timeout.ms,45000), (ha.health-monitor.rpc.connect.max.retries,1), (ha.health-monitor.sleep-after-disconnect.ms,1000), (ha.zookeeper.acl,world:anyone:rwcda), (ha.zookeeper.parent-znode,/hadoop-ha), (ha.zookeeper.session-timeout.ms,10000), (hadoop.caller.context.enabled,false), (hadoop.caller.context.max.size,128), (hadoop.caller.context.signature.max.size,40), (hadoop.common.configuration.version,3.0.0), (hadoop.domainname.resolver.impl,org.apache.hadoop.net.DNSDomainNameResolver), (hadoop.http.authentication.kerberos.keytab,${user.home}/hadoop.keytab), (hadoop.http.authentication.kerberos.principal,HTTP/_HOST@LOCALHOST), (hadoop.http.authentication.signature.secret.file,*********(redacted)), (hadoop.http.authentication.simple.anonymous.allowed,true), (hadoop.http.authentication.token.validity,*********(redacted)), (hadoop.http.authentication.type,simple), (hadoop.http.cross-origin.allowed-headers,X-Requested-With,Content-Type,Accept,Origin), (hadoop.http.cross-origin.allowed-methods,GET,POST,HEAD), (hadoop.http.cross-origin.allowed-origins,*), (hadoop.http.cross-origin.enabled,false), (hadoop.http.cross-origin.max-age,1800), (hadoop.http.filter.initializers,org.apache.hadoop.http.lib.StaticUserWebFilter), (hadoop.http.idle_timeout.ms,60000), (hadoop.http.logs.enabled,true), (hadoop.http.sni.host.check.enabled,false), (hadoop.http.staticuser.user,dr.who), (hadoop.jetty.logs.serve.aliases,true), (hadoop.kerberos.keytab.login.autorenewal.enabled,false), (hadoop.kerberos.kinit.command,kinit), (hadoop.kerberos.min.seconds.before.relogin,60), (hadoop.metrics.jvm.use-thread-mxbean,false), (hadoop.prometheus.endpoint.enabled,false), (hadoop.registry.jaas.context,Client), (hadoop.registry.secure,false), (hadoop.registry.system.acls,sasl:yarn@, sasl:mapred@, sasl:hdfs@), (hadoop.registry.zk.connection.timeout.ms,15000), (hadoop.registry.zk.quorum,localhost:2181), (hadoop.registry.zk.retry.ceiling.ms,60000), (hadoop.registry.zk.retry.interval.ms,1000), (hadoop.registry.zk.retry.times,5), (hadoop.registry.zk.root,/registry), (hadoop.registry.zk.session.timeout.ms,60000), (hadoop.rpc.protection,authentication), (hadoop.rpc.socket.factory.class.default,org.apache.hadoop.net.StandardSocketFactory), (hadoop.security.auth_to_local.mechanism,hadoop), (hadoop.security.authentication,simple), (hadoop.security.authorization,false), (hadoop.security.credential.clear-text-fallback,true), (hadoop.security.crypto.buffer.size,8192), (hadoop.security.crypto.cipher.suite,AES/CTR/NoPadding), (hadoop.security.crypto.codec.classes.aes.ctr.nopadding,org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec), (hadoop.security.dns.log-slow-lookups.enabled,false), (hadoop.security.dns.log-slow-lookups.threshold.ms,1000), (hadoop.security.group.mapping,org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback), (hadoop.security.group.mapping.ldap.connection.timeout.ms,60000), (hadoop.security.group.mapping.ldap.conversion.rule,none), (hadoop.security.group.mapping.ldap.directory.search.timeout,10000), (hadoop.security.group.mapping.ldap.num.attempts,3), (hadoop.security.group.mapping.ldap.num.attempts.before.failover,3), (hadoop.security.group.mapping.ldap.posix.attr.gid.name,gidNumber), (hadoop.security.group.mapping.ldap.posix.attr.uid.name,uidNumber), (hadoop.security.group.mapping.ldap.read.timeout.ms,60000), (hadoop.security.group.mapping.ldap.search.attr.group.name,cn), (hadoop.security.group.mapping.ldap.search.attr.member,member), (hadoop.security.group.mapping.ldap.search.filter.group,(objectClass=group)), (hadoop.security.group.mapping.ldap.search.filter.user,(&(objectClass=user)(sAMAccountName={0}))), (hadoop.security.group.mapping.ldap.search.group.hierarchy.levels,0), (hadoop.security.group.mapping.ldap.ssl,false), (hadoop.security.group.mapping.providers.combined,true), (hadoop.security.groups.cache.background.reload,false), (hadoop.security.groups.cache.background.reload.threads,3), (hadoop.security.groups.cache.secs,300), (hadoop.security.groups.cache.warn.after.ms,5000), (hadoop.security.groups.negative-cache.secs,30), (hadoop.security.groups.shell.command.timeout,0s), (hadoop.security.instrumentation.requires.admin,false), (hadoop.security.java.secure.random.algorithm,SHA1PRNG), (hadoop.security.key.default.bitlength,128), (hadoop.security.key.default.cipher,AES/CTR/NoPadding), (hadoop.security.kms.client.authentication.retry-count,1), (hadoop.security.kms.client.encrypted.key.cache.expiry,43200000), (hadoop.security.kms.client.encrypted.key.cache.low-watermark,0.3f), (hadoop.security.kms.client.encrypted.key.cache.num.refill.threads,2), (hadoop.security.kms.client.encrypted.key.cache.size,500), (hadoop.security.kms.client.failover.sleep.base.millis,100), (hadoop.security.kms.client.failover.sleep.max.millis,2000), (hadoop.security.kms.client.timeout,60), (hadoop.security.random.device.file.path,/dev/urandom), (hadoop.security.secure.random.impl,org.apache.hadoop.crypto.random.OpensslSecureRandom), (hadoop.security.sensitive-config-keys,*********(redacted)), (hadoop.security.token.service.use_ip,*********(redacted)), (hadoop.security.uid.cache.secs,14400), (hadoop.service.shutdown.timeout,30s), (hadoop.shell.missing.defaultFs.warning,false), (hadoop.shell.safely.delete.limit.num.files,100), (hadoop.ssl.client.conf,ssl-client.xml), (hadoop.ssl.enabled.protocols,TLSv1.2), (hadoop.ssl.hostname.verifier,DEFAULT), (hadoop.ssl.keystores.factory.class,org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory), (hadoop.ssl.require.client.cert,false), (hadoop.ssl.server.conf,ssl-server.xml), (hadoop.system.tags,YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
[2024-10-24T01:29:40.961+0000] {spark_submit.py:524} INFO - ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL), (hadoop.tags.system,YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
[2024-10-24T01:29:40.963+0000] {spark_submit.py:524} INFO - ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL), (hadoop.tmp.dir,/tmp/hadoop-${user.name}), (hadoop.user.group.static.mapping.overrides,dr.who=;), (hadoop.util.hash.type,murmur), (hadoop.workaround.non.threadsafe.getpwuid,true), (hadoop.zk.acl,world:anyone:rwcda), (hadoop.zk.num-retries,1000), (hadoop.zk.retry-interval-ms,1000), (hadoop.zk.timeout-ms,10000), (io.bytes.per.checksum,512), (io.compression.codec.bzip2.library,system-native), (io.erasurecode.codec.rs-legacy.rawcoders,rs-legacy_java), (io.erasurecode.codec.rs.rawcoders,rs_native,rs_java), (io.erasurecode.codec.xor.rawcoders,xor_native,xor_java), (io.file.buffer.size,65536), (io.map.index.interval,128), (io.map.index.skip,0), (io.mapfile.bloom.error.rate,0.005), (io.mapfile.bloom.size,1048576), (io.seqfile.compress.blocksize,1000000), (io.seqfile.local.dir,${hadoop.tmp.dir}/io/local), (io.serializations,org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization), (io.skip.checksum.errors,false), (ipc.[port_number].backoff.enable,false), (ipc.[port_number].callqueue.impl,java.util.concurrent.LinkedBlockingQueue), (ipc.[port_number].cost-provider.impl,org.apache.hadoop.ipc.DefaultCostProvider), (ipc.[port_number].decay-scheduler.backoff.responsetime.enable,false), (ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds,10s,20s,30s,40s), (ipc.[port_number].decay-scheduler.decay-factor,0.5), (ipc.[port_number].decay-scheduler.metrics.top.user.count,10), (ipc.[port_number].decay-scheduler.period-ms,5000), (ipc.[port_number].decay-scheduler.thresholds,13,25,50), (ipc.[port_number].faircallqueue.multiplexer.weights,8,4,2,1), (ipc.[port_number].identity-provider.impl,org.apache.hadoop.ipc.UserIdentityProvider), (ipc.[port_number].scheduler.impl,org.apache.hadoop.ipc.DefaultRpcScheduler), (ipc.[port_number].scheduler.priority.levels,4), (ipc.[port_number].weighted-cost.handler,1), (ipc.[port_number].weighted-cost.lockexclusive,100), (ipc.[port_number].weighted-cost.lockfree,1), (ipc.[port_number].weighted-cost.lockshared,10), (ipc.[port_number].weighted-cost.response,1), (ipc.client.bind.wildcard.addr,false), (ipc.client.connect.max.retries,10), (ipc.client.connect.max.retries.on.timeouts,45), (ipc.client.connect.retry.interval,1000), (ipc.client.connect.timeout,20000), (ipc.client.connection.maxidletime,10000), (ipc.client.fallback-to-simple-auth-allowed,false), (ipc.client.idlethreshold,4000), (ipc.client.kill.max,10), (ipc.client.low-latency,false), (ipc.client.ping,true), (ipc.client.rpc-timeout.ms,0), (ipc.client.tcpnodelay,true), (ipc.maximum.data.length,134217728), (ipc.maximum.response.length,134217728), (ipc.ping.interval,60000), (ipc.server.listen.queue.size,256), (ipc.server.log.slow.rpc,false), (ipc.server.max.connections,0), (ipc.server.purge.interval,15), (ipc.server.reuseaddr,true), (map.sort.class,org.apache.hadoop.util.QuickSort), (mapreduce.am.max-attempts,2), (mapreduce.app-submission.cross-platform,false), (mapreduce.client.completion.pollinterval,5000), (mapreduce.client.libjars.wildcard,true), (mapreduce.client.output.filter,FAILED), (mapreduce.client.progressmonitor.pollinterval,1000), (mapreduce.client.submit.file.replication,10), (mapreduce.cluster.acls.enabled,false), (mapreduce.cluster.local.dir,${hadoop.tmp.dir}/mapred/local), (mapreduce.fileoutputcommitter.algorithm.version,1), (mapreduce.fileoutputcommitter.task.cleanup.enabled,false), (mapreduce.framework.name,local), (mapreduce.ifile.readahead,true), (mapreduce.ifile.readahead.bytes,4194304), (mapreduce.input.fileinputformat.list-status.num-threads,1), (mapreduce.input.fileinputformat.split.minsize,0), (mapreduce.input.lineinputformat.linespermap,1), (mapreduce.job.acl-modify-job, ), (mapreduce.job.acl-view-job, ), (mapreduce.job.cache.limit.max-resources,0), (mapreduce.job.cache.limit.max-resources-mb,0), (mapreduce.job.cache.limit.max-single-resource-mb,0), (mapreduce.job.classloader,false), (mapreduce.job.committer.setup.cleanup.needed,true), (mapreduce.job.complete.cancel.delegation.tokens,*********(redacted)), (mapreduce.job.counters.max,120), (mapreduce.job.dfs.storage.capacity.kill-limit-exceed,false), (mapreduce.job.emit-timeline-data,false), (mapreduce.job.encrypted-intermediate-data,false), (mapreduce.job.encrypted-intermediate-data-key-size-bits,128), (mapreduce.job.encrypted-intermediate-data.buffer.kb,128), (mapreduce.job.end-notification.max.attempts,5), (mapreduce.job.end-notification.max.retry.interval,5000), (mapreduce.job.end-notification.retry.attempts,0), (mapreduce.job.end-notification.retry.interval,1000), (mapreduce.job.finish-when-all-reducers-done,true), (mapreduce.job.hdfs-servers,${fs.defaultFS}), (mapreduce.job.heap.memory-mb.ratio,0.8), (mapreduce.job.local-fs.single-disk-limit.bytes,-1), (mapreduce.job.local-fs.single-disk-limit.check.interval-ms,5000), (mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed,true), (mapreduce.job.map.output.collector.class,org.apache.hadoop.mapred.MapTask$MapOutputBuffer), (mapreduce.job.maps,2), (mapreduce.job.max.map,-1), (mapreduce.job.max.split.locations,15), (mapreduce.job.maxtaskfailures.per.tracker,3), (mapreduce.job.queuename,default), (mapreduce.job.reduce.shuffle.consumer.plugin.class,org.apache.hadoop.mapreduce.task.reduce.Shuffle), (mapreduce.job.reduce.slowstart.completedmaps,0.05), (mapreduce.job.reducer.preempt.delay.sec,0), (mapreduce.job.reducer.unconditional-preempt.delay.sec,300), (mapreduce.job.reduces,1), (mapreduce.job.running.map.limit,0), (mapreduce.job.running.reduce.limit,0), (mapreduce.job.sharedcache.mode,disabled), (mapreduce.job.speculative.minimum-allowed-tasks,10), (mapreduce.job.speculative.retry-after-no-speculate,1000), (mapreduce.job.speculative.retry-after-speculate,15000), (mapreduce.job.speculative.slowtaskthreshold,1.0), (mapreduce.job.speculative.speculative-cap-running-tasks,0.1), (mapreduce.job.speculative.speculative-cap-total-tasks,0.01), (mapreduce.job.split.metainfo.maxsize,10000000), (mapreduce.job.token.tracking.ids.enabled,*********(redacted)), (mapreduce.job.ubertask.enable,false), (mapreduce.job.ubertask.maxmaps,9), (mapreduce.job.ubertask.maxreduces,1), (mapreduce.jobhistory.address,0.0.0.0:10020), (mapreduce.jobhistory.admin.acl,*), (mapreduce.jobhistory.admin.address,0.0.0.0:10033), (mapreduce.jobhistory.always-scan-user-dir,false), (mapreduce.jobhistory.cleaner.enable,true), (mapreduce.jobhistory.cleaner.interval-ms,86400000), (mapreduce.jobhistory.client.thread-count,10), (mapreduce.jobhistory.datestring.cache.size,200000), (mapreduce.jobhistory.done-dir,${yarn.app.mapreduce.am.staging-dir}/history/done), (mapreduce.jobhistory.http.policy,HTTP_ONLY), (mapreduce.jobhistory.intermediate-done-dir,${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate), (mapreduce.jobhistory.intermediate-user-done-dir.permissions,770), (mapreduce.jobhistory.jhist.format,binary), (mapreduce.jobhistory.joblist.cache.size,20000), (mapreduce.jobhistory.jobname.limit,50), (mapreduce.jobhistory.keytab,/etc/security/keytab/jhs.service.keytab), (mapreduce.jobhistory.loadedjob.tasks.max,-1), (mapreduce.jobhistory.loadedjobs.cache.size,5), (mapreduce.jobhistory.max-age-ms,604800000), (mapreduce.jobhistory.minicluster.fixed.ports,false), (mapreduce.jobhistory.move.interval-ms,180000), (mapreduce.jobhistory.move.thread-count,3), (mapreduce.jobhistory.principal,jhs/_HOST@REALM.TLD), (mapreduce.jobhistory.recovery.enable,false), (mapreduce.jobhistory.recovery.store.class,org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService), (mapreduce.jobhistory.recovery.store.fs.uri,${hadoop.tmp.dir}/mapred/history/recoverystore), (mapreduce.jobhistory.recovery.store.leveldb.path,${hadoop.tmp.dir}/mapred/history/recoverystore), (mapreduce.jobhistory.webapp.address,0.0.0.0:19888), (mapreduce.jobhistory.webapp.https.address,0.0.0.0:19890), (mapreduce.jobhistory.webapp.rest-csrf.custom-header,X-XSRF-Header), (mapreduce.jobhistory.webapp.rest-csrf.enabled,false), (mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore,GET,OPTIONS,HEAD), (mapreduce.jobhistory.webapp.xfs-filter.xframe-options,SAMEORIGIN), (mapreduce.jvm.system-properties-to-log,os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name), (mapreduce.map.cpu.vcores,1), (mapreduce.map.log.level,INFO), (mapreduce.map.maxattempts,4), (mapreduce.map.memory.mb,-1), (mapreduce.map.output.compress,false), (mapreduce.map.output.compress.codec,org.apache.hadoop.io.compress.DefaultCodec), (mapreduce.map.skip.maxrecords,0), (mapreduce.map.skip.proc-count.auto-incr,true), (mapreduce.map.sort.spill.percent,0.80), (mapreduce.map.speculative,true), (mapreduce.output.fileoutputformat.compress,false), (mapreduce.output.fileoutputformat.compress.codec,org.apache.hadoop.io.compress.DefaultCodec), (mapreduce.output.fileoutputformat.compress.type,RECORD), (mapreduce.outputcommitter.factory.scheme.s3a,org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory), (mapreduce.reduce.cpu.vcores,1), (mapreduce.reduce.input.buffer.percent,0.0), (mapreduce.reduce.log.level,INFO), (mapreduce.reduce.markreset.buffer.percent,0.0), (mapreduce.reduce.maxattempts,4), (mapreduce.reduce.memory.mb,-1), (mapreduce.reduce.merge.inmem.threshold,1000), (mapreduce.reduce.shuffle.connect.timeout,180000), (mapreduce.reduce.shuffle.fetch.retry.enabled,${yarn.nodemanager.recovery.enabled}), (mapreduce.reduce.shuffle.fetch.retry.interval-ms,1000), (mapreduce.reduce.shuffle.fetch.retry.timeout-ms,30000), (mapreduce.reduce.shuffle.input.buffer.percent,0.70), (mapreduce.reduce.shuffle.memory.limit.percent,0.25), (mapreduce.reduce.shuffle.merge.percent,0.66), (mapreduce.reduce.shuffle.parallelcopies,5), (mapreduce.reduce.shuffle.read.timeout,180000), (mapreduce.reduce.shuffle.retry-delay.max.ms,60000), (mapreduce.reduce.skip.maxgroups,0), (mapreduce.reduce.skip.proc-count.auto-incr,true), (mapreduce.reduce.speculative,true), (mapreduce.shuffle.connection-keep-alive.enable,false), (mapreduce.shuffle.connection-keep-alive.timeout,5), (mapreduce.shuffle.listen.queue.size,128), (mapreduce.shuffle.max.connections,0), (mapreduce.shuffle.max.threads,0), (mapreduce.shuffle.pathcache.concurrency-level,16), (mapreduce.shuffle.pathcache.expire-after-access-minutes,5), (mapreduce.shuffle.pathcache.max-weight,10485760), (mapreduce.shuffle.port,13562), (mapreduce.shuffle.ssl.enabled,false), (mapreduce.shuffle.ssl.file.buffer.size,65536), (mapreduce.shuffle.transfer.buffer.size,131072), (mapreduce.task.combine.progress.records,10000), (mapreduce.task.exit.timeout,60000), (mapreduce.task.exit.timeout.check-interval-ms,20000), (mapreduce.task.files.preserve.failedtasks,false), (mapreduce.task.io.sort.factor,10), (mapreduce.task.io.sort.mb,100), (mapreduce.task.local-fs.write-limit.bytes,-1), (mapreduce.task.merge.progress.records,10000), (mapreduce.task.profile,false), (mapreduce.task.profile.map.params,${mapreduce.task.profile.params}), (mapreduce.task.profile.maps,0-2), (mapreduce.task.profile.params,-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s), (mapreduce.task.profile.reduce.params,${mapreduce.task.profile.params}), (mapreduce.task.profile.reduces,0-2), (mapreduce.task.skip.start.attempts,2), (mapreduce.task.stuck.timeout-ms,600000), (mapreduce.task.timeout,600000), (mapreduce.task.userlog.limit.kb,0), (net.topology.impl,org.apache.hadoop.net.NetworkTopology), (net.topology.node.switch.mapping.impl,org.apache.hadoop.net.ScriptBasedMapping), (net.topology.script.number.args,100), (nfs.exports.allowed.hosts,* rw), (rpc.metrics.quantile.enable,false), (rpc.metrics.timeunit,MILLISECONDS), (seq.io.sort.factor,100), (seq.io.sort.mb,100), (tfile.fs.input.buffer.size,262144), (tfile.fs.output.buffer.size,262144), (tfile.io.chunk.size,1048576), (yarn.acl.enable,false), (yarn.acl.reservation-enable,false), (yarn.admin.acl,*), (yarn.am.liveness-monitor.expiry-interval-ms,600000), (yarn.app.attempt.diagnostics.limit.kc,64), (yarn.app.mapreduce.am.command-opts,-Xmx1024m), (yarn.app.mapreduce.am.container.log.backups,0), (yarn.app.mapreduce.am.container.log.limit.kb,0), (yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size,10), (yarn.app.mapreduce.am.hard-kill-timeout-ms,10000), (yarn.app.mapreduce.am.job.committer.cancel-timeout,60000), (yarn.app.mapreduce.am.job.committer.commit-window,10000), (yarn.app.mapreduce.am.job.task.listener.thread-count,30), (yarn.app.mapreduce.am.log.level,INFO), (yarn.app.mapreduce.am.resource.cpu-vcores,1), (yarn.app.mapreduce.am.resource.mb,1536), (yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms,1000), (yarn.app.mapreduce.am.staging-dir,/tmp/hadoop-yarn/staging), (yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled,false), (yarn.app.mapreduce.am.webapp.https.client.auth,false), (yarn.app.mapreduce.am.webapp.https.enabled,false), (yarn.app.mapreduce.client-am.ipc.max-retries,3), (yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts,3), (yarn.app.mapreduce.client.job.max-retries,3), (yarn.app.mapreduce.client.job.retry-interval,2000), (yarn.app.mapreduce.client.max-retries,3), (yarn.app.mapreduce.shuffle.log.backups,0), (yarn.app.mapreduce.shuffle.log.limit.kb,0), (yarn.app.mapreduce.shuffle.log.separate,true), (yarn.app.mapreduce.task.container.log.backups,0), (yarn.client.application-client-protocol.poll-interval-ms,200), (yarn.client.application-client-protocol.poll-timeout-ms,-1), (yarn.client.failover-no-ha-proxy-provider,org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider), (yarn.client.failover-proxy-provider,org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider), (yarn.client.failover-retries,0), (yarn.client.failover-retries-on-socket-timeouts,0), (yarn.client.load.resource-types.from-server,false), (yarn.client.max-cached-nodemanagers-proxies,0), (yarn.client.nodemanager-client-async.thread-pool-max-size,500), (yarn.client.nodemanager-connect.max-wait-ms,180000), (yarn.client.nodemanager-connect.retry-interval-ms,10000), (yarn.cluster.max-application-priority,0), (yarn.dispatcher.cpu-monitor.samples-per-min,60), (yarn.dispatcher.drain-events.timeout,300000), (yarn.dispatcher.print-events-info.threshold,5000), (yarn.fail-fast,false), (yarn.federation.cache-ttl.secs,300), (yarn.federation.enabled,false), (yarn.federation.registry.base-dir,yarnfederation/), (yarn.federation.state-store.class,org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore), (yarn.federation.subcluster-resolver.class,org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl), (yarn.http.policy,HTTP_ONLY), (yarn.intermediate-data-encryption.enable,false), (yarn.ipc.rpc.class,org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC), (yarn.is.minicluster,false), (yarn.log-aggregation-enable,false), (yarn.log-aggregation-status.time-out.ms,600000), (yarn.log-aggregation.debug.filesize,104857600), (yarn.log-aggregation.file-controller.TFile.class,org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController), (yarn.log-aggregation.file-formats,TFile), (yarn.log-aggregation.retain-check-interval-seconds,-1), (yarn.log-aggregation.retain-seconds,-1), (yarn.minicluster.control-resource-monitoring,false), (yarn.minicluster.fixed.ports,false), (yarn.minicluster.use-rpc,false), (yarn.minicluster.yarn.nodemanager.resource.memory-mb,4096), (yarn.nm.liveness-monitor.expiry-interval-ms,600000), (yarn.node-attribute.fs-store.impl.class,org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore), (yarn.node-labels.configuration-type,centralized), (yarn.node-labels.enabled,false), (yarn.node-labels.fs-store.impl.class,org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore), (yarn.nodemanager.address,${yarn.nodemanager.hostname}:0), (yarn.nodemanager.admin-env,MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX), (yarn.nodemanager.amrmproxy.address,0.0.0.0:8049), (yarn.nodemanager.amrmproxy.client.thread-count,25), (yarn.nodemanager.amrmproxy.enabled,false), (yarn.nodemanager.amrmproxy.ha.enable,false), (yarn.nodemanager.amrmproxy.interceptor-class.pipeline,org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor), (yarn.nodemanager.aux-services.manifest.enabled,false), (yarn.nodemanager.aux-services.manifest.reload-ms,0), (yarn.nodemanager.aux-services.mapreduce_shuffle.class,org.apache.hadoop.mapred.ShuffleHandler), (yarn.nodemanager.collector-service.address,${yarn.nodemanager.hostname}:8048), (yarn.nodemanager.collector-service.thread-count,5), (yarn.nodemanager.container-diagnostics-maximum-size,10000), (yarn.nodemanager.container-executor.class,org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor), (yarn.nodemanager.container-executor.exit-code-file.timeout-ms,2000), (yarn.nodemanager.container-localizer.java.opts,-Xmx256m), (yarn.nodemanager.container-localizer.log.level,INFO), (yarn.nodemanager.container-log-monitor.dir-size-limit-bytes,1000000000), (yarn.nodemanager.container-log-monitor.enable,false), (yarn.nodemanager.container-log-monitor.interval-ms,60000), (yarn.nodemanager.container-log-monitor.total-size-limit-bytes,10000000000), (yarn.nodemanager.container-manager.thread-count,20), (yarn.nodemanager.container-metrics.enable,true), (yarn.nodemanager.container-metrics.period-ms,-1), (yarn.nodemanager.container-metrics.unregister-delay-ms,10000), (yarn.nodemanager.container-monitor.enabled,true), (yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled,false), (yarn.nodemanager.container-retry-minimum-interval-ms,1000), (yarn.nodemanager.container.stderr.pattern,{*stderr*,*STDERR*}), (yarn.nodemanager.container.stderr.tail.bytes,4096), (yarn.nodemanager.containers-launcher.class,org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher), (yarn.nodemanager.default-container-executor.log-dirs.permissions,710), (yarn.nodemanager.delete.debug-delay-sec,0), (yarn.nodemanager.delete.thread-count,4), (yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled,true), (yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled,true), (yarn.nodemanager.disk-health-checker.enable,true), (yarn.nodemanager.disk-health-checker.interval-ms,120000), (yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage,90.0), (yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb,0), (yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb,0), (yarn.nodemanager.disk-health-checker.min-healthy-disks,0.25), (yarn.nodemanager.disk-validator,basic), (yarn.nodemanager.distributed-scheduling.enabled,false), (yarn.nodemanager.elastic-memory-control.enabled,false), (yarn.nodemanager.elastic-memory-control.oom-handler,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler), (yarn.nodemanager.elastic-memory-control.timeout-sec,5), (yarn.nodemanager.emit-container-events,true), (yarn.nodemanager.env-whitelist,JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ), (yarn.nodemanager.health-checker.interval-ms,600000), (yarn.nodemanager.health-checker.run-before-startup,false), (yarn.nodemanager.health-checker.scripts,script), (yarn.nodemanager.health-checker.timeout-ms,1200000), (yarn.nodemanager.hostname,0.0.0.0), (yarn.nodemanager.keytab,/etc/krb5.keytab), (yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms,20), (yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms,1000), (yarn.nodemanager.linux-container-executor.cgroups.hierarchy,/hadoop-yarn), (yarn.nodemanager.linux-container-executor.cgroups.mount,false), (yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage,false), (yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users,true), (yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user,nobody), (yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern,^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$), (yarn.nodemanager.linux-container-executor.resources-handler.class,org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler), (yarn.nodemanager.local-cache.max-files-per-directory,8192), (yarn.nodemanager.local-dirs,${hadoop.tmp.dir}/nm-local-dir), (yarn.nodemanager.localizer.address,${yarn.nodemanager.hostname}:8040), (yarn.nodemanager.localizer.cache.cleanup.interval-ms,600000), (yarn.nodemanager.localizer.cache.target-size-mb,10240), (yarn.nodemanager.localizer.client.thread-count,5), (yarn.nodemanager.localizer.fetch.thread-count,4), (yarn.nodemanager.log-aggregation.compression-type,none), (yarn.nodemanager.log-aggregation.num-log-files-per-app,30), (yarn.nodemanager.log-aggregation.policy.class,org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy), (yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds,-1), (yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min,3600), (yarn.nodemanager.log-container-debug-info.enabled,true), (yarn.nodemanager.log-dirs,${yarn.log.dir}/userlogs), (yarn.nodemanager.log.deletion-threads-count,4), (yarn.nodemanager.log.retain-seconds,10800), (yarn.nodemanager.logaggregation.threadpool-size-max,100), (yarn.nodemanager.node-attributes.provider.fetch-interval-ms,600000), (yarn.nodemanager.node-attributes.provider.fetch-timeout-ms,1200000), (yarn.nodemanager.node-attributes.resync-interval-ms,120000), (yarn.nodemanager.node-labels.provider.fetch-interval-ms,600000), (yarn.nodemanager.node-labels.provider.fetch-timeout-ms,1200000), (yarn.nodemanager.node-labels.resync-interval-ms,120000), (yarn.nodemanager.numa-awareness.enabled,false), (yarn.nodemanager.numa-awareness.numactl.cmd,/usr/bin/numactl), (yarn.nodemanager.numa-awareness.read-topology,false), (yarn.nodemanager.opportunistic-containers-max-queue-length,0), (yarn.nodemanager.opportunistic-containers-use-pause-for-preemption,false), (yarn.nodemanager.pluggable-device-framework.enabled,false), (yarn.nodemanager.pmem-check-enabled,true), (yarn.nodemanager.process-kill-wait.ms,5000), (yarn.nodemanager.recovery.compaction-interval-secs,3600), (yarn.nodemanager.recovery.dir,${hadoop.tmp.dir}/yarn-nm-recovery), (yarn.nodemanager.recovery.enabled,false), (yarn.nodemanager.recovery.supervised,false), (yarn.nodemanager.remote-app-log-dir,/tmp/logs), (yarn.nodemanager.remote-app-log-dir-include-older,true), (yarn.nodemanager.remote-app-log-dir-suffix,logs), (yarn.nodemanager.resource-monitor.interval-ms,3000), (yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices,auto), (yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class,org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin), (yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices,auto), (yarn.nodemanager.resource-plugins.gpu.docker-plugin,nvidia-docker-v1), (yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint,http://localhost:3476/v1.0/docker/cli), (yarn.nodemanager.resource.count-logical-processors-as-cores,false), (yarn.nodemanager.resource.cpu-vcores,-1), (yarn.nodemanager.resource.detect-hardware-capabilities,false), (yarn.nodemanager.resource.memory-mb,-1), (yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage,90.0), (yarn.nodemanager.resource.memory.cgroups.swappiness,0), (yarn.nodemanager.resource.memory.enabled,false), (yarn.nodemanager.resource.memory.enforced,true), (yarn.nodemanager.resource.pcores-vcores-multiplier,1.0), (yarn.nodemanager.resource.percentage-physical-cpu-limit,100), (yarn.nodemanager.resource.system-reserved-memory-mb,-1), (yarn.nodemanager.resourcemanager.minimum.version,NONE), (yarn.nodemanager.runtime.linux.allowed-runtimes,default), (yarn.nodemanager.runtime.linux.docker.allowed-container-networks,host,none,bridge), (yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes,runc), (yarn.nodemanager.runtime.linux.docker.capabilities,CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE), (yarn.nodemanager.runtime.linux.docker.default-container-network,host), (yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed,false), (yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed,true), (yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed,false), (yarn.nodemanager.runtime.linux.docker.image-update,false), (yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed,false), (yarn.nodemanager.runtime.linux.docker.stop.grace-period,10), (yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold,1), (yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold,1), (yarn.nodemanager.runtime.linux.runc.allowed-container-networks,host,none,bridge), (yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes,runc), (yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size,500), (yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs,360), (yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed,false), (yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin), (yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs,60), (yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file,/runc-root/image-tag-to-hash), (yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache,10), (yarn.nodemanager.runtime.linux.runc.image-toplevel-dir,/runc-root), (yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs,600), (yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep,100), (yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin,org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin), (yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed,false), (yarn.nodemanager.runtime.linux.sandbox-mode,disabled), (yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions,read), (yarn.nodemanager.sleep-delay-before-sigkill.ms,250), (yarn.nodemanager.vmem-check-enabled,true), (yarn.nodemanager.vmem-pmem-ratio,2.1), (yarn.nodemanager.webapp.address,${yarn.nodemanager.hostname}:8042), (yarn.nodemanager.webapp.cross-origin.enabled,false), (yarn.nodemanager.webapp.https.address,0.0.0.0:8044), (yarn.nodemanager.webapp.rest-csrf.custom-header,X-XSRF-Header), (yarn.nodemanager.webapp.rest-csrf.enabled,false), (yarn.nodemanager.webapp.rest-csrf.methods-to-ignore,GET,OPTIONS,HEAD), (yarn.nodemanager.webapp.xfs-filter.xframe-options,SAMEORIGIN), (yarn.nodemanager.windows-container.cpu-limit.enabled,false), (yarn.nodemanager.windows-container.memory-limit.enabled,false), (yarn.registry.class,org.apache.hadoop.registry.client.impl.FSRegistryOperationsService), (yarn.resourcemanager.activities-manager.app-activities.max-queue-length,100), (yarn.resourcemanager.activities-manager.app-activities.ttl-ms,600000), (yarn.resourcemanager.activities-manager.cleanup-interval-ms,5000), (yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms,600000), (yarn.resourcemanager.address,${yarn.resourcemanager.hostname}:8032), (yarn.resourcemanager.admin.address,${yarn.resourcemanager.hostname}:8033), (yarn.resourcemanager.admin.client.thread-count,1), (yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs,*********(redacted)), (yarn.resourcemanager.am.max-attempts,2), (yarn.resourcemanager.amlauncher.thread-count,50), (yarn.resourcemanager.application-https.policy,NONE), (yarn.resourcemanager.application-tag-based-placement.enable,false), (yarn.resourcemanager.application-timeouts.monitor.interval-ms,3000), (yarn.resourcemanager.application.max-tag.length,100), (yarn.resourcemanager.application.max-tags,10), (yarn.resourcemanager.auto-update.containers,false), (yarn.resourcemanager.client.thread-count,50), (yarn.resourcemanager.configuration.file-system-based-store,/yarn/conf), (yarn.resourcemanager.configuration.provider-class,org.apache.hadoop.yarn.LocalConfigurationProvider), (yarn.resourcemanager.connect.max-wait.ms,900000), (yarn.resourcemanager.connect.retry-interval.ms,30000), (yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs,*********(redacted)), (yarn.resourcemanager.container.liveness-monitor.interval-ms,600000), (yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs,20), (yarn.resourcemanager.delayed.delegation-token.removal-interval-ms,*********(redacted)), (yarn.resourcemanager.delegation-token-renewer.thread-count,*********(redacted)), (yarn.resourcemanager.delegation-token-renewer.thread-retry-interval,*********(redacted)), (yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts,*********(redacted)), (yarn.resourcemanager.delegation-token-renewer.thread-timeout,*********(redacted)), (yarn.resourcemanager.delegation-token.always-cancel,*********(redacted)), (yarn.resourcemanager.delegation-token.max-conf-size-bytes,*********(redacted)), (yarn.resourcemanager.delegation.key.update-interval,86400000), (yarn.resourcemanager.delegation.token.max-lifetime,*********(redacted)), (yarn.resourcemanager.delegation.token.renew-interval,*********(redacted)), (yarn.resourcemanager.epoch.range,0), (yarn.resourcemanager.fail-fast,${yarn.fail-fast}), (yarn.resourcemanager.fs.state-store.num-retries,0), (yarn.resourcemanager.fs.state-store.retry-interval-ms,1000), (yarn.resourcemanager.fs.state-store.uri,${hadoop.tmp.dir}/yarn/system/rmstore), (yarn.resourcemanager.ha.automatic-failover.embedded,true), (yarn.resourcemanager.ha.automatic-failover.enabled,true), (yarn.resourcemanager.ha.automatic-failover.zk-base-path,/yarn-leader-election), (yarn.resourcemanager.ha.enabled,false), (yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size,10), (yarn.resourcemanager.hostname,0.0.0.0), (yarn.resourcemanager.keytab,/etc/krb5.keytab), (yarn.resourcemanager.leveldb-state-store.compaction-interval-secs,3600), (yarn.resourcemanager.leveldb-state-store.path,${hadoop.tmp.dir}/yarn/system/rmstore), (yarn.resourcemanager.max-completed-applications,1000), (yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory,10), (yarn.resourcemanager.metrics.runtime.buckets,60,300,1440), (yarn.resourcemanager.nm-container-queuing.load-comparator,QUEUE_LENGTH), (yarn.resourcemanager.nm-container-queuing.max-queue-length,15), (yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms,100), (yarn.resourcemanager.nm-container-queuing.min-queue-length,5), (yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms,10), (yarn.resourcemanager.nm-container-queuing.queue-limit-stdev,1.0f), (yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms,1000), (yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs,*********(redacted)), (yarn.resourcemanager.node-ip-cache.expiry-interval-secs,-1), (yarn.resourcemanager.node-labels.provider.fetch-interval-ms,1800000), (yarn.resourcemanager.node-removal-untracked.timeout-ms,60000), (yarn.resourcemanager.nodemanager-connect-retries,10), (yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs,3600), (yarn.resourcemanager.nodemanager.minimum.version,NONE), (yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms,1000), (yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms,1000), (yarn.resourcemanager.nodemanagers.heartbeat-interval-ms,1000), (yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable,false), (yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor,1.0), (yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor,1.0), (yarn.resourcemanager.opportunistic-container-allocation.enabled,false), (yarn.resourcemanager.opportunistic-container-allocation.nodes-used,10), (yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat,-1), (yarn.resourcemanager.placement-constraints.algorithm.class,org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm), (yarn.resourcemanager.placement-constraints.algorithm.iterator,SERIAL), (yarn.resourcemanager.placement-constraints.algorithm.pool-size,1), (yarn.resourcemanager.placement-constraints.handler,disabled), (yarn.resourcemanager.placement-constraints.retry-attempts,3), (yarn.resourcemanager.placement-constraints.scheduler.pool-size,1), (yarn.resourcemanager.proxy-user-privileges.enabled,false), (yarn.resourcemanager.proxy.connection.timeout,60000), (yarn.resourcemanager.proxy.timeout.enabled,true), (yarn.resourcemanager.recovery.enabled,false), (yarn.resourcemanager.reservation-system.enable,false), (yarn.resourcemanager.reservation-system.planfollower.time-step,1000), (yarn.resourcemanager.resource-profiles.enabled,false), (yarn.resourcemanager.resource-profiles.source-file,resource-profiles.json), (yarn.resourcemanager.resource-tracker.address,${yarn.resourcemanager.hostname}:8031), (yarn.resourcemanager.resource-tracker.client.thread-count,50), (yarn.resourcemanager.resource-tracker.nm.ip-hostname-check,false), (yarn.resourcemanager.rm.container-allocation.expiry-interval-ms,600000), (yarn.resourcemanager.scheduler.address,${yarn.resourcemanager.hostname}:8030), (yarn.resourcemanager.scheduler.class,org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler), (yarn.resourcemanager.scheduler.client.thread-count,50), (yarn.resourcemanager.scheduler.monitor.enable,false), (yarn.resourcemanager.scheduler.monitor.policies,org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy), (yarn.resourcemanager.state-store.max-completed-applications,${yarn.resourcemanager.max-completed-applications}), (yarn.resourcemanager.store.class,org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore), (yarn.resourcemanager.submission-preprocessor.enabled,false), (yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms,60000), (yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size,10), (yarn.resourcemanager.system-metrics-publisher.enabled,false), (yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size,1000), (yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch,false), (yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds,60), (yarn.resourcemanager.webapp.address,${yarn.resourcemanager.hostname}:8088), (yarn.resourcemanager.webapp.cross-origin.enabled,false), (yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled,*********(redacted)), (yarn.resourcemanager.webapp.https.address,${yarn.resourcemanager.hostname}:8090), (yarn.resourcemanager.webapp.rest-csrf.custom-header,X-XSRF-Header), (yarn.resourcemanager.webapp.rest-csrf.enabled,false), (yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore,GET,OPTIONS,HEAD), (yarn.resourcemanager.webapp.ui-actions.enabled,true), (yarn.resourcemanager.webapp.xfs-filter.xframe-options,SAMEORIGIN), (yarn.resourcemanager.work-preserving-recovery.enabled,true), (yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms,10000), (yarn.resourcemanager.zk-appid-node.split-index,0), (yarn.resourcemanager.zk-delegation-token-node.split-index,*********(redacted)), (yarn.resourcemanager.zk-max-znode-size.bytes,1048576), (yarn.resourcemanager.zk-state-store.parent-path,/rmstore), (yarn.rm.system-metrics-publisher.emit-container-events,false), (yarn.router.clientrm.interceptor-class.pipeline,org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor), (yarn.router.interceptor.user.threadpool-size,5), (yarn.router.pipeline.cache-max-size,25), (yarn.router.rmadmin.interceptor-class.pipeline,org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor), (yarn.router.webapp.address,0.0.0.0:8089), (yarn.router.webapp.https.address,0.0.0.0:8091), (yarn.router.webapp.interceptor-class.pipeline,org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST), (yarn.scheduler.configuration.fs.path,file://${hadoop.tmp.dir}/yarn/system/schedconf), (yarn.scheduler.configuration.leveldb-store.compaction-interval-secs,86400), (yarn.scheduler.configuration.leveldb-store.path,${hadoop.tmp.dir}/yarn/system/confstore), (yarn.scheduler.configuration.max.version,100), (yarn.scheduler.configuration.mutation.acl-policy.class,org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy), (yarn.scheduler.configuration.store.class,file), (yarn.scheduler.configuration.store.max-logs,1000), (yarn.scheduler.configuration.zk-store.parent-path,/confstore), (yarn.scheduler.include-port-in-node-name,false), (yarn.scheduler.maximum-allocation-mb,8192), (yarn.scheduler.maximum-allocation-vcores,4), (yarn.scheduler.minimum-allocation-mb,1024), (yarn.scheduler.minimum-allocation-vcores,1), (yarn.scheduler.queue-placement-rules,user-group), (yarn.sharedcache.admin.address,0.0.0.0:8047), (yarn.sharedcache.admin.thread-count,1), (yarn.sharedcache.app-checker.class,org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker), (yarn.sharedcache.checksum.algo.impl,org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl), (yarn.sharedcache.cleaner.initial-delay-mins,10), (yarn.sharedcache.cleaner.period-mins,1440), (yarn.sharedcache.cleaner.resource-sleep-ms,0), (yarn.sharedcache.client-server.address,0.0.0.0:8045), (yarn.sharedcache.client-server.thread-count,50), (yarn.sharedcache.enabled,false), (yarn.sharedcache.nested-level,3), (yarn.sharedcache.nm.uploader.replication.factor,10), (yarn.sharedcache.nm.uploader.thread-count,20), (yarn.sharedcache.root-dir,/sharedcache), (yarn.sharedcache.store.class,org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore), (yarn.sharedcache.store.in-memory.check-period-mins,720), (yarn.sharedcache.store.in-memory.initial-delay-mins,10), (yarn.sharedcache.store.in-memory.staleness-period-mins,10080), (yarn.sharedcache.uploader.server.address,0.0.0.0:8046), (yarn.sharedcache.uploader.server.thread-count,50), (yarn.sharedcache.webapp.address,0.0.0.0:8788), (yarn.system-metrics-publisher.enabled,false), (yarn.timeline-service.address,${yarn.timeline-service.hostname}:10200), (yarn.timeline-service.app-aggregation-interval-secs,15), (yarn.timeline-service.app-collector.linger-period.ms,60000), (yarn.timeline-service.client.best-effort,false), (yarn.timeline-service.client.drain-entities.timeout.ms,2000), (yarn.timeline-service.client.fd-clean-interval-secs,60), (yarn.timeline-service.client.fd-flush-interval-secs,10), (yarn.timeline-service.client.fd-retain-secs,300), (yarn.timeline-service.client.internal-timers-ttl-secs,420), (yarn.timeline-service.client.max-retries,30), (yarn.timeline-service.client.retry-interval-ms,1000), (yarn.timeline-service.enabled,false), (yarn.timeline-service.entity-group-fs-store.active-dir,/tmp/entity-file-history/active), (yarn.timeline-service.entity-group-fs-store.app-cache-size,10), (yarn.timeline-service.entity-group-fs-store.cache-store-class,org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore), (yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds,3600), (yarn.timeline-service.entity-group-fs-store.done-dir,/tmp/entity-file-history/done/), (yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size,10485760), (yarn.timeline-service.entity-group-fs-store.retain-seconds,604800), (yarn.timeline-service.entity-group-fs-store.scan-interval-seconds,60), (yarn.timeline-service.entity-group-fs-store.summary-store,org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore), (yarn.timeline-service.entity-group-fs-store.with-user-dir,false), (yarn.timeline-service.flowname.max-size,0), (yarn.timeline-service.generic-application-history.max-applications,10000), (yarn.timeline-service.handler-thread-count,10), (yarn.timeline-service.hbase-schema.prefix,prod.), (yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds,259200000), (yarn.timeline-service.hbase.coprocessor.jar.hdfs.location,/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar), (yarn.timeline-service.hostname,0.0.0.0), (yarn.timeline-service.http-authentication.simple.anonymous.allowed,true), (yarn.timeline-service.http-authentication.type,simple), (yarn.timeline-service.http-cross-origin.enabled,false), (yarn.timeline-service.keytab,/etc/krb5.keytab), (yarn.timeline-service.leveldb-state-store.path,${hadoop.tmp.dir}/yarn/timeline), (yarn.timeline-service.leveldb-timeline-store.path,${hadoop.tmp.dir}/yarn/timeline), (yarn.timeline-service.leveldb-timeline-store.read-cache-size,104857600), (yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size,10000), (yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size,10000), (yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms,300000), (yarn.timeline-service.reader.class,org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl), (yarn.timeline-service.reader.webapp.address,${yarn.timeline-service.webapp.address}), (yarn.timeline-service.reader.webapp.https.address,${yarn.timeline-service.webapp.https.address}), (yarn.timeline-service.recovery.enabled,false), (yarn.timeline-service.state-store-class,org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore), (yarn.timeline-service.store-class,org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore), (yarn.timeline-service.timeline-client.number-of-async-entities-to-merge,10), (yarn.timeline-service.ttl-enable,true), (yarn.timeline-service.ttl-ms,604800000), (yarn.timeline-service.version,1.0f), (yarn.timeline-service.webapp.address,${yarn.timeline-service.hostname}:8188), (yarn.timeline-service.webapp.https.address,${yarn.timeline-service.hostname}:8190), (yarn.timeline-service.webapp.rest-csrf.custom-header,X-XSRF-Header), (yarn.timeline-service.webapp.rest-csrf.enabled,false), (yarn.timeline-service.webapp.rest-csrf.methods-to-ignore,GET,OPTIONS,HEAD), (yarn.timeline-service.webapp.xfs-filter.xframe-options,SAMEORIGIN), (yarn.timeline-service.writer.async.queue.capacity,100), (yarn.timeline-service.writer.class,org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl), (yarn.timeline-service.writer.flush-interval-seconds,60), (yarn.webapp.api-service.enable,false), (yarn.webapp.enable-rest-app-submissions,true), (yarn.webapp.filter-entity-list-by-user,false), (yarn.webapp.filter-invalid-xml-chars,false), (yarn.webapp.ui2.enable,false), (yarn.webapp.xfs-filter.enabled,true), (yarn.workflow-id.tag-prefix,workflowid:)), Metrics Properties -> Vector((*.sink.servlet.class,org.apache.spark.metrics.sink.MetricsServlet), (*.sink.servlet.path,/metrics/json), (applications.sink.servlet.path,/metrics/applications/json), (master.sink.servlet.path,/metrics/master/json)), System Properties -> Vector((SPARK_SUBMIT,true), (awt.toolkit,sun.awt.X11.XToolkit), (file.encoding,UTF-8), (file.separator,/), (java.awt.graphicsenv,sun.awt.X11GraphicsEnvironment), (java.awt.printerjob,sun.print.PSPrinterJob), (java.class.version,55.0), (java.home,/usr/lib/jvm/java-11-openjdk-amd64), (java.io.tmpdir,/tmp), (java.library.path,/usr/local/lib:/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib), (java.runtime.name,OpenJDK Runtime Environment), (java.runtime.version,11.0.25+9-post-Debian-1deb11u1), (java.specification.maintenance.version,3), (java.specification.name,Java Platform API Specification), (java.specification.vendor,Oracle Corporation), (java.specification.version,11), (java.vendor,Debian), (java.vendor.url,https://tracker.debian.org/openjdk-11), (java.vendor.url.bug,https://bugs.debian.org/openjdk-11), (java.version,11.0.25), (java.version.date,2024-10-15), (java.vm.compressedOopsMode,32-bit), (java.vm.info,mixed mode, sharing), (java.vm.name,OpenJDK 64-Bit Server VM), (java.vm.specification.name,Java Virtual Machine Specification), (java.vm.specification.vendor,Oracle Corporation), (java.vm.specification.version,11), (java.vm.vendor,Debian), (java.vm.version,11.0.25+9-post-Debian-1deb11u1), (jdk.debug,release), (jdk.reflect.useDirectMethodHandle,false), (jetty.git.hash,cef3fbd6d736a21e7d541a5db490381d95a2047d), (line.separator,
[2024-10-24T01:29:41.082+0000] {spark_submit.py:524} INFO - ), (os.arch,amd64), (os.name,Linux), (os.version,5.15.0-124-generic), (path.separator,:), (sun.arch.data.model,64), (sun.boot.library.path,/usr/lib/jvm/java-11-openjdk-amd64/lib), (sun.cpu.endian,little), (sun.cpu.isalist,), (sun.io.unicode.encoding,UnicodeLittle), (sun.java.command,org.apache.spark.deploy.SparkSubmit --master spark://spark-master:7077 --name arrow-spark --queue root.default jobs/silver/api_openbrewerydb.py), (sun.java.launcher,SUN_STANDARD), (sun.jnu.encoding,UTF-8), (sun.management.compiler,HotSpot 64-Bit Tiered Compilers), (sun.os.patch.level,unknown), (user.dir,/opt/***), (user.home,/home/***), (user.language,en), (user.name,***), (user.timezone,Etc/UTC)), JVM Information -> List((Java Home,/usr/lib/jvm/java-11-openjdk-amd64), (Java Version,11.0.25 (Debian)), (Scala Version,version 2.12.18)))) by listener AppStatusListener took 1.267807969s.
[2024-10-24T01:29:42.679+0000] {spark_submit.py:524} INFO - 24/10/24 01:29:41 INFO AsyncEventQueue: Process of event SparkListenerApplicationStart(IngestaoSilver,Some(app-20241024012741-0046),1729733248237,***,None,None,None) by listener AppStatusListener took 6.364025877s.
[2024-10-24T01:30:53.431+0000] {spark_submit.py:524} INFO - 24/10/24 01:30:53 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-10-24T01:31:13.680+0000] {spark_submit.py:524} INFO - 24/10/24 01:31:13 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@665c71b0)) by listener AppStatusListener took 7.036687523s.
[2024-10-24T01:32:09.990+0000] {spark_submit.py:524} INFO - 24/10/24 01:32:08 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@5ed0f9b8)) by listener AppStatusListener took 2.029677143s.
[2024-10-24T01:33:27.219+0000] {spark_submit.py:524} INFO - 24/10/24 01:33:25 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@bb4e4b6)) by listener AppStatusListener took 1.008901725s.
[2024-10-24T01:33:59.949+0000] {spark_submit.py:524} INFO - 24/10/24 01:33:59 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@164008)) by listener AppStatusListener took 19.663865563s.
[2024-10-24T01:34:16.757+0000] {spark_submit.py:524} INFO - 24/10/24 01:34:16 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@5c2704b)) by listener AppStatusListener took 1.351930599s.
[2024-10-24T01:35:25.341+0000] {spark_submit.py:524} INFO - Hello from Spark!
[2024-10-24T01:35:25.356+0000] {spark_submit.py:524} INFO - 24/10/24 01:35:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2024-10-24T01:35:25.466+0000] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-10-24T01:35:25.524+0000] {process_utils.py:131} INFO - Sending 15 to group 8819. PIDs of all processes in the group: [8831, 9571, 8819]
[2024-10-24T01:35:25.552+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 8819
[2024-10-24T01:35:25.561+0000] {taskinstance.py:1630} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-10-24T01:35:25.563+0000] {spark_submit.py:654} INFO - Sending kill signal to spark-submit
[2024-10-24T01:35:25.700+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 183, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 438, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 492, in _process_spark_submit_log
    for line in itr:
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 1632, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-10-24T01:35:25.763+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=api_openbrewerydb_to_silver_gold, task_id=Silver, execution_date=20231128T080000, start_date=20241024T012657, end_date=20241024T013525
[2024-10-24T01:35:25.848+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 137 for task Silver (Task received SIGTERM signal; 8819)
[2024-10-24T01:35:25.903+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=8831, status='terminated', started='01:26:57') (8831) terminated with exit code None
[2024-10-24T01:35:25.905+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=8819, status='terminated', exitcode=1, started='01:26:56') (8819) terminated with exit code 1
[2024-10-24T01:35:25.906+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=9571, status='terminated', started='01:27:19') (9571) terminated with exit code None
[2024-10-24T14:34:39.286+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509
[2024-10-24T14:34:39.287+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver'
[2024-10-24T14:34:39.315+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509
[2024-10-24T14:34:39.315+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver'
[2024-10-24T14:34:39.344+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [queued]>
[2024-10-24T14:34:39.350+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [queued]>
[2024-10-24T14:34:39.350+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2024-10-24T14:34:39.360+0000] {taskinstance.py:1380} INFO - Executing <Task(SparkSubmitOperator): Silver> on 2023-11-28 08:00:00+00:00
[2024-10-24T14:34:39.364+0000] {standard_task_runner.py:57} INFO - Started process 12338 to run task
[2024-10-24T14:34:39.366+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_openbrewerydb_to_silver_gold', 'Silver', 'scheduled__2023-11-28T08:00:00+00:00', '--job-id', '81', '--raw', '--subdir', 'DAGS_FOLDER/api_openbrewerydb_to_silver.py', '--cfg-path', '/tmp/tmp8pu0lwkc']
[2024-10-24T14:34:39.368+0000] {standard_task_runner.py:85} INFO - Job 81: Subtask Silver
[2024-10-24T14:34:39.414+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509
[2024-10-24T14:34:39.414+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=api_openbrewerydb_to_silver_gold/run_id=scheduled__2023-11-28T08:00:00+00:00/task_id=Silver'
[2024-10-24T14:34:39.415+0000] {task_command.py:415} INFO - Running <TaskInstance: api_openbrewerydb_to_silver_gold.Silver scheduled__2023-11-28T08:00:00+00:00 [running]> on host 96f89615839b
[2024-10-24T14:34:39.494+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Rodrigo Araujo' AIRFLOW_CTX_DAG_ID='api_openbrewerydb_to_silver_gold' AIRFLOW_CTX_TASK_ID='Silver' AIRFLOW_CTX_EXECUTION_DATE='2023-11-28T08:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-11-28T08:00:00+00:00'
[2024-10-24T14:34:39.505+0000] {base.py:73} INFO - Using connection ID 'spark-conn' for task execution.
[2024-10-24T14:34:39.506+0000] {spark_submit.py:363} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --name arrow-spark jobs/silver/api_openbrewerydb.py
[2024-10-24T14:34:42.332+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkContext: Running Spark version 3.5.3
[2024-10-24T14:34:42.334+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkContext: OS info Linux, 5.15.0-124-generic, amd64
[2024-10-24T14:34:42.335+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkContext: Java version 11.0.25
[2024-10-24T14:34:42.411+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-10-24T14:34:42.509+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceUtils: ==============================================================
[2024-10-24T14:34:42.510+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-10-24T14:34:42.510+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceUtils: ==============================================================
[2024-10-24T14:34:42.511+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkContext: Submitted application: IngestaoSilver
[2024-10-24T14:34:42.541+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-10-24T14:34:42.558+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceProfile: Limiting resource is cpu
[2024-10-24T14:34:42.559+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-10-24T14:34:42.612+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SecurityManager: Changing view acls to: ***
[2024-10-24T14:34:42.612+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SecurityManager: Changing modify acls to: ***
[2024-10-24T14:34:42.613+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SecurityManager: Changing view acls groups to:
[2024-10-24T14:34:42.613+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SecurityManager: Changing modify acls groups to:
[2024-10-24T14:34:42.614+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2024-10-24T14:34:42.883+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO Utils: Successfully started service 'sparkDriver' on port 43877.
[2024-10-24T14:34:42.913+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkEnv: Registering MapOutputTracker
[2024-10-24T14:34:42.951+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkEnv: Registering BlockManagerMaster
[2024-10-24T14:34:42.975+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-10-24T14:34:42.976+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-10-24T14:34:42.979+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-10-24T14:34:43.000+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4806539f-8f7f-4740-b7c3-153f38f11193
[2024-10-24T14:34:43.014+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-10-24T14:34:43.030+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-10-24T14:34:43.176+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2024-10-24T14:34:43.226+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-10-24T14:34:43.343+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2024-10-24T14:34:43.387+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.2:7077 after 26 ms (0 ms spent in bootstraps)
[2024-10-24T14:34:43.480+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20241024143443-0076
[2024-10-24T14:34:43.483+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20241024143443-0076/0 on worker-20241024142308-172.18.0.5-43899 (172.18.0.5:43899) with 2 core(s)
[2024-10-24T14:34:43.485+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20241024143443-0076/0 on hostPort 172.18.0.5:43899 with 2 core(s), 1024.0 MiB RAM
[2024-10-24T14:34:43.492+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42757.
[2024-10-24T14:34:43.492+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO NettyBlockTransferService: Server created on 96f89615839b:42757
[2024-10-24T14:34:43.496+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2024-10-24T14:34:43.507+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 96f89615839b, 42757, None)
[2024-10-24T14:34:43.511+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20241024143443-0076/0 is now RUNNING
[2024-10-24T14:34:43.511+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO BlockManagerMasterEndpoint: Registering block manager 96f89615839b:42757 with 434.4 MiB RAM, BlockManagerId(driver, 96f89615839b, 42757, None)
[2024-10-24T14:34:43.514+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 96f89615839b, 42757, None)
[2024-10-24T14:34:43.516+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 96f89615839b, 42757, None)
[2024-10-24T14:34:43.790+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2024-10-24T14:34:43.989+0000] {spark_submit.py:524} INFO - Hello from Spark!
[2024-10-24T14:34:43.990+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2024-10-24T14:34:43.999+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:43 INFO SparkUI: Stopped Spark web UI at http://96f89615839b:4040
[2024-10-24T14:34:44.004+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO StandaloneSchedulerBackend: Shutting down all executors
[2024-10-24T14:34:44.008+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2024-10-24T14:34:44.024+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-10-24T14:34:44.035+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO MemoryStore: MemoryStore cleared
[2024-10-24T14:34:44.035+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO BlockManager: BlockManager stopped
[2024-10-24T14:34:44.040+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-10-24T14:34:44.042+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-10-24T14:34:44.051+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO SparkContext: Successfully stopped SparkContext
[2024-10-24T14:34:44.409+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO ShutdownHookManager: Shutdown hook called
[2024-10-24T14:34:44.410+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-54fcc4bb-7c05-4f3d-acec-b23ceb423525/pyspark-17a16487-d050-4f45-a26b-cd5b19c16453
[2024-10-24T14:34:44.414+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-54fcc4bb-7c05-4f3d-acec-b23ceb423525
[2024-10-24T14:34:44.417+0000] {spark_submit.py:524} INFO - 24/10/24 14:34:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-6d417417-fb88-43f8-88e7-121f2b4ec846
[2024-10-24T14:34:44.498+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=api_openbrewerydb_to_silver_gold, task_id=Silver, execution_date=20231128T080000, start_date=20241024T143439, end_date=20241024T143444
[2024-10-24T14:34:44.516+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-10-24T14:34:44.536+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
